---
slug: openai-api-safe
title: Safely handle the OpenAI AI API key for use in web and mobile apps
# Safely call the OpenAI AI API from web and mobile apps
date: 2025-01-31
tags: [guides]
authors: depombo
---

A key concern when building a web or mobile application that uses OpenAI’s language models is protecting your private API key. But if you’re a beginning developer or an experienced developer wanting to build an MVP quickly, setting up a full-fledged backend just to safely handle an API key can feel like a drag. In this article, you’ll learn how keep your OpenAI API key safe while keeping your code and infrastructure as simple as possible.

## Why You Can’t Store Your OpenAI Key on the Front End

Putting your API key directly in client-side code (HTML, JavaScript, or mobile apps) is very risky.

```typescript title="client/openai.ts"
import OpenAI from "openai";

const client = new OpenAI({
  dangerouslyAllowBrowser: true,
  apiKey: 'sk-proj-YOURSECRETKEY',
});

const completion = await OpenAI.instance.chat(...)
```

Anyone can inspect your code (even if it is minified), extract your key, and abuse it. This misuse can:
	•	Lead to unexpected costs on your OpenAI account
	•	Violate OpenAI’s Acceptable Use Policy and Terms of Service
	•	Potentially expose your project to spam or abusive behavior

Hence, you need a layer of protection that keeps the secret key away from the end user’s browser or device.

## Why You Can't Call the OpenAI API from the Front End through an unauthenticated proxy

Putting your OpenAI API key as a secret in a hosted server or cloud function and calling it is better than exposing it in your backend directly, but it is still unsafe. Let's take the following cloud function

```js title="openai.ts"

const completion = await fetch("https://functionroute.yourcloud.com/chat", {
	method: 'POST',
	headers: {
		'Content-Type': 'application/json',
	},
	...,
});

```


Let's take the following cloud function snippet

```typescript title="cloud/function.ts"
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: env.OPENAI_SECRET_KEY,
});

```




The exposed endpoint 

## Why You Can’t Call the OpenAI API Key from the Front End through an authenticated proxy with generic permissions


## Building proper permissions and authentication into your backend


## Use a Backend-as-a-Service (BaaS) Platform to abstract this complexity

If you don’t want to manage a backend with proper authentication and permissions, a Backend-as-a-Service (BaaS) platform can act as a secure middleman between your front end and OpenAI. The idea is straightforward:
	1.	Store Your Key Securely
Store environment variables (like your OpenAI key) in a protected configuration that users cannot see.
	2.	Get a proxy with permissions and authentication
Most BaaS providers let you set up custom logic or routes without dealing with servers. You define a small piece of code (or a “function”) that runs on their infrastructure.
	3.	Process Requests
	•	Your front end sends a request to this BaaS endpoint (passing along the user’s prompt or text) on behalf of your user.
	•	The endpoint verifies this request belongs to one of your users. attaches your secret API key from the secure store.
	•	The request goes to OpenAI, then returns the AI-generated response to your front end.

From your perspective, there’s “no backend” to manage—no servers, no DevOps, no complicated configurations. But under the hood, the BaaS handles all the server details, authentication and permissioning for you.