---
slug: openai-api-safety
title: OpenAI API key safety and mistakes in client-side code
# Safe use and common mistakes of the OpenAI API key in client apps
# 3 security mistakes when using the OpenAI API with apps
# Safely call the OpenAI AI API from web and mobile apps
# Common pitfalls when using the OpenAI API usage in/with apps
date: 2025-02-03
tags: [guides]
authors: depombo
---

A key concern when building a web or mobile application that uses OpenAI’s language models is protecting your private API key. If you want to keep complexity low and release features quickly, setting up a fully fledged backend just to safeguard an API key can lead to overengineering. In this article, you’ll learn how to avoid the most common security mistakes when integrating the OpenAI API into a client-side app—without sacrificing simplicity or safety. Overlooking these pitfalls can leave the door open to OpenAI API misuse, which can:
 - Lead to unexpected costs on your OpenAI account
 - Violate OpenAI’s Acceptable Use Policy and Terms of Service
 - Potentially expose your project to spam or abusive behavior

## Mistake # 1: Store the OpenAI Key in the frontend

Putting your API key directly in client-side code (using any type of web or mobile framework) as shown in the sample frontend code below is simple, but also very risky.

```javascript title="client/openai.ts"
import OpenAI from "openai";

const client = new OpenAI({
  dangerouslyAllowBrowser: true,
  apiKey: 'sk-proj-YOURSECRETKEY',
});

const completion = await OpenAI.instance.chat(...)
```

<!--truncate-->

Anyone can inspect your code (even if it is minified or obfuscated somehow), extract your key, and abuse it. 

Don't let [this](https://community.openai.com/t/repeated-fraudulent-use-of-my-api-keys/510465/3) happen to you. The OpenAI SDK requires the `dangerouslyAllowBrowser` flag to try to prevent this problem and make sure you add a layer of protection that keeps the secret key away from the end user’s browser or device.

## Mistake # 2: Call the OpenAI API client-side through an unauthenticated proxy

Putting your OpenAI API key as a secret in a hosted server or cloud function and calling that endpoint from your client is much better than exposing it directly, but it is still unsafe. Let's take the following client-side application code:

```js title="client/openai.ts"

const opair = await fetch("https://functionroute.yourcloud.com/v1/chat/completions", {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({...})
});

```

Alongside the cloud function OpenAI API proxy it is calling and is defined as follows:

```typescript title="cloud/function.ts"
import route from "yourcloud";

route.get('/', req, res => {
  const opair = await fetch(`https://api.openai.com/${req.path}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authentication': `Bearer ${env.OPENAI_SECRET_KEY}`

    },
    body: req.body.clone(),
  });
  return res.send(opair);
})

```

Per Mistake # 1, we know that anyone can inspect your client-side code and (ab)use the exposed OpenAI proxy endpoint directly at `https://functionroute.yourcloud.com/`.

## Mistake # 3: Call the OpenAI API client-side through an authenticated proxy with generic permissions

Putting your OpenAI API key as a secret in a hosted server or cloud function and adding authentication so only your users can call the proxy endpoint is quite common and still much better than the previous two flawed setups. However, it is *still* unsafe. Let's take the following frontend code:

```js title="client/openai.ts"
import supabase from "supabase-js";

const jwt = supabase.auth.session().access_token;

const opair = await fetch("https://functionroute.yourcloud.com/v1/chat/completion", {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authentication': `Bearer ${jwt}`
  },
  body: JSON.stringify({...}),
});

```

Alongside the cloud function OpenAI API proxy it is calling and is defined as follows:

```typescript title="cloud/function.ts"
import route from "yourcloud";
import { createRemoteJWKSet, jwtVerify } from 'jose'

const JWKS = createRemoteJWKSet(new URL('https://<YOUR-PROJECT-REF>.supabase.co/auth/v1/.well-known/jwks.json'))

route.get('/', req, res => {
	const authHeader = req.headers['authorization'];
  try {
    // 1. Get the token from the Authorization header
    const authHeader = req.headers['authorization'] || ''
    const jwt = authHeader.split(' ')[1] // Bearer <token>

    if (!jwt) {
      return res.status(401).json({ error: 'No token provided' })
    }

    // 2. Verify the token using the JWKS
    const { payload } = await jwtVerify(token, JWKS)

    // 3. The token is valid
    const opair = await fetch(`https://api.openai.com/${req.path}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authentication': `Bearer ${env.OPENAI_SECRET_KEY}`

      },
      body: req.body.clone(),
    });
    return res.send(opair);

  } catch (error) {
    console.error(error)
    return res.status(401).json({ error: 'Invalid token' })
  }
})

```

This LLM API implementation for a client-side app looks fine at first glance and provides some safety. However, there are two problems with it:

1. There are no limits to how many times a given user can call the OpenAI API proxy. Any user can call this API proxy up to the global rate limit of the Open AI secret key stored in the server by simply getting their JWT and calling the proxy at `https://functionroute.yourcloud.com/v1/`. The JWTs, or authentication tokens, typically expire within an hour. That means that someone can generate a token from your client-side code and (mis)use it until it expires. Then rinse and repeat.
2. OpenAI, and other LLM APIs, have endpoints that allow uploading [files](https://platform.openai.com/docs/api-reference/files) to be analyzed and sensitive chat histories within [Threads](https://platform.openai.com/docs/api-reference/threads). The proxy layed out above does not provide any permissions or access control over which users uploaded or created which private resources. This means that any user with just their JWT can exploit this security vulnerability and see all the files and conversations ever created with that OpenAI API key. This will cause infringements to your user's data and privacy. The following frontend code below will call this OpenAI API [endpoint](https://platform.openai.com/docs/api-reference/files/list) which will return all the files uploaded across all your users.

```js title="vulnerability.ts"
import supabase from "supabase-js";

const jwt = supabase.auth.session().access_token;

const opair = await fetch("https://functionroute.yourcloud.com/v1/files", {
  method: 'GET',
  headers: {
    'Content-Type': 'application/json',
    'Authentication': `Bearer ${jwt}`
  },
  body: JSON.stringify({...}),
});

```

## Building proper permissions, usage per user and authentication into your backend

This ensures that only the users who create these types of resources can continue to access them.

Rate Limiting

Access control and permissions

## Use a Backend-as-a-Service (BaaS) Platform to abstract this complexity

If you don’t want to manage a backend with proper authentication and permissions, a Backend-as-a-Service (BaaS) platform can act as a secure middleman between your front end and OpenAI. The idea is straightforward:
	1.	Store Your Key Securely
Store environment variables (like your OpenAI key) in a protected configuration that users cannot see.
	2.	Process Requests with permissions and authentication
	•	Your front end sends a request to this BaaS endpoint on behalf of your user.
	•	The endpoint verifies this request belongs to one of your users, the user hasn't gone past their limits  and attaches your secret API key from the secure store.
	•	The request goes to OpenAI, then returns the AI-generated response to your front end.

From your perspective, there’s “no backend” to manage—no servers, no DevOps, no complicated configurations. But under the hood, the BaaS handles all the server details, authentication and permissioning for you.