# Backmesh

> Firebase for LLM APIs

## Important notes

- How Backmesh works: Backmesh is a proxy deployed close to your users that sits between your web or mobile app and the LLM APIs.
- LLM User Analytics without packages: All LLM API calls are instrumented so you can identify usage patterns, reduce costs and improve user satisfaction within your AI applications.

## Optional

- [Pricing](https://backmesh.com/pricing)
- [Docs](https://backmesh.com/docs)
- [Blog](https://backmesh.com/blog)
- [Files](https://platform.openai.com/docs/api-reference/files)
- [Threads](https://platform.openai.com/docs/api-reference/threads)